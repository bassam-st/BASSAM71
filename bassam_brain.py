# bassam_brain.py
import os
from pathlib import Path

# Ù…ÙƒØ§Ù† Ø§Ù„Ù†ÙˆØ§Ø©
MODEL_PATH = os.getenv("BASSAM_MODEL", "models/tinyllama-1.1b-chat.gguf")

def load_model():
    if not Path(MODEL_PATH).exists():
        raise FileNotFoundError(
            f"âš ï¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ {MODEL_PATH}. "
            "Ù†Ø²Ù‘Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¶Ø¹Ù‡ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ models Ø£Ùˆ Ø¹Ø¯Ù‘Ù„ Ø§Ù„Ø±Ø§Ø¨Ø·."
        )
    print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {MODEL_PATH}")
    # Ù‡Ù†Ø§ ØªØ¶ÙŠÙ ÙƒÙˆØ¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ù…Ø«Ù„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… llama.cpp Ø£Ùˆ Ù…ÙƒØªØ¨Ø© Ø£Ø®Ø±Ù‰)

def ask_brain(prompt: str) -> str:
    # Ø­Ø§Ù„ÙŠØ§Ù‹ Ù…Ø¬Ø±Ø¯ Ø±Ø¯ ØªØ¬Ø±ÙŠØ¨ÙŠ
    return f"ðŸ¤– (ØªØ¬Ø±ÙŠØ¨ÙŠ) Ø§Ø³ØªÙ„Ù…Øª Ø³Ø¤Ø§Ù„Ùƒ: {prompt}"
